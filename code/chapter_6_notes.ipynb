{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Encoder\n",
    "\n",
    "Looking to draw a line of connection between the Game State object created in chapter 3 and the encode. \n",
    "To visualize this concept we will use a super simple game state of a 3x3 tic-tac-toe board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The board looks like in its 2D array (or a rank 2 tensor) form: [['X', ' ', ' '], [' ', 'O', ' '], [' ', ' ', 'X']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class GameState:\n",
    "    def __init__(self):\n",
    "        self.board = [[' ' for _ in range(3)] for _ in range(3)]\n",
    "    \n",
    "    def place_stone(self, x, y, player):\n",
    "        \"\"\"Place a stone ('X' or 'O') at position (x, y)\"\"\"\n",
    "        self.board[x][y] = player\n",
    "    \n",
    "\n",
    "# initializing the game state and making moves \n",
    "game_state = GameState()\n",
    "game_state.place_stone(0, 0, 'X')\n",
    "game_state.place_stone(1, 1, 'O')\n",
    "game_state.place_stone(2, 2, 'X')\n",
    "\n",
    "print(\"The board looks like in its 2D array (or a rank 2 tensor) form:\", game_state.board )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded State: [1 0 0 0 2 0 0 0 1]\n",
      "Encoded Point (0, 1) as index: 1\n",
      "Decoded index 1 back to point: (0, 1)\n"
     ]
    }
   ],
   "source": [
    "class SimpleEncoder:\n",
    "\n",
    "    \"\"\"\n",
    "    This is the exact same encoder as the one in chapter 6 but scaled down to tic-tac-toe\n",
    "    This is only an Index  encorder, not a value encorder (i.e. translated (row number,  column number) to some index in a list)\n",
    "    \"\"\"\n",
    "\n",
    "    def name(self):\n",
    "        return \"SimpleEncoder\"\n",
    "    \n",
    "    def encode(self, game_state):\n",
    "        \"\"\"\n",
    "        Encode the game state into a flat list\n",
    "        We are itterating over each 3 item row and putting each cell into a flat list \n",
    "        \"\"\"\n",
    "\n",
    "        flat_list = []\n",
    "        for row in game_state.board:\n",
    "            for cell in row:\n",
    "                if cell == ' ':\n",
    "                    flat_list.append(0)\n",
    "                elif cell == 'X':\n",
    "                    flat_list.append(1)\n",
    "                elif cell == 'O':\n",
    "                    flat_list.append(2)\n",
    "        return np.array(flat_list)\n",
    "    \n",
    "    def encode_point(self, x, y):\n",
    "        \"\"\"\n",
    "        Encode a point into an integer index\n",
    "        \n",
    "        Note: we calcuate the index only, the \n",
    "        \"\"\"\n",
    "        return 3 * x + y\n",
    "    \n",
    "    def decode_point_index(self, index):\n",
    "        \"\"\"Decoding an integer index into a point (x, y)\"\"\"\n",
    "        return divmod(index, 3)\n",
    "    \n",
    "    # def num_points(self):\n",
    "    #     return 3 * 3\n",
    "    \n",
    "    # def shape(self):\n",
    "    #     return (3, 3)\n",
    "\n",
    "encoder = SimpleEncoder()\n",
    "encoded_state = encoder.encode(game_state)\n",
    "print(\"Encoded State:\", encoded_state)\n",
    "\n",
    "encoded_point = encoder.encode_point(0, 1)\n",
    "decoded_point = encoder.decode_point_index(encoded_point)\n",
    "print(f\"Encoded Point (0, 1) as index: {encoded_point}\")\n",
    "print(f\"Decoded index {encoded_point} back to point: {decoded_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Encoder by Type\n",
    "\n",
    "Stating the obvious perhaps but this is useful because it will let us handle multiple encoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import enum\n",
    "from collections import namedtuple\n",
    "\n",
    "def get_encoder_by_name(name, board_size):\n",
    "    if isinstance(board_size, int):\n",
    "        board_size = (board_size, board_size)\n",
    "    module = importlib.import_module('dlgo.encoders.' + name)\n",
    "    constructor = getattr(module, 'create')\n",
    "    return constructor(board_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you interact with the unique encoders like so...\n",
    "\n",
    "encoder1 = get_encoder_by_name('oneplane', 19)\n",
    "encoder2 = get_encoder_by_name('simple', 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Go Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# this will generate 20 go games using Monte Calro as desribed in the book\n",
    "python generate_mcts_games.py -n 20 --board-out features.npy --move-out labels.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras API Overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "export TF_CPP_MIN_LOG_LEVEL=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 0 is most logs, 3 is none\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 392)               307720    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 196)               77028     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1970      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 386718 (1.48 MB)\n",
      "Trainable params: 386718 (1.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# running a familiar example from chapter 5 but using Keras \n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(392, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(196, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1200/1200 [==============================] - 2s 1ms/step - loss: 0.0892 - accuracy: 0.2339\n",
      "Epoch 2/2\n",
      "1200/1200 [==============================] - 2s 1ms/step - loss: 0.0891 - accuracy: 0.2436\n",
      "313/313 [==============================] - 0s 944us/step - loss: 0.0891 - accuracy: 0.2535\n",
      "Test loss: 0.08906501531600952\n",
      "Test accuracy: 0.2535000145435333\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=50,\n",
    "          epochs=2)\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Go bot training \n",
    "\n",
    "## Loading preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(123)\n",
    "X = np.load('/home/locutus/Desktop/dlgo_fork/deep_learning_and_the_game_of_go_with_notes/code/generated_games/features-20.npy')\n",
    "Y = np.load('/home/locutus/Desktop/dlgo_fork/deep_learning_and_the_game_of_go_with_notes/code/generated_games/labels-20.npy')\n",
    "samples = X.shape[0]\n",
    "board_size = 9 * 9\n",
    "\n",
    "X = X.reshape(samples, board_size)\n",
    "Y = Y.reshape(samples, board_size)\n",
    "\n",
    "train_samples = int(0.9 * samples)\n",
    "X_train, X_test = X[:train_samples], X[train_samples:]\n",
    "Y_train, Y_test = Y[:train_samples], Y[train_samples:]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu', input_shape=(board_size,)),\n",
    "    tf.keras.layers.Dense(units=board_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 1000)              82000     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 81)                40581     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 623081 (2.38 MB)\n",
      "Trainable params: 623081 (2.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2610 - accuracy: 0.0147 - val_loss: 0.2515 - val_accuracy: 0.0082\n",
      "Epoch 2/2\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.0147 - val_loss: 0.2349 - val_accuracy: 0.0082\n",
      "Test loss: 0.23489025235176086\n",
      "Test accuracy: 0.008196720853447914\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='sigmoid', input_shape=(board_size,)))\n",
    "model.add(Dense(500, activation='sigmoid'))\n",
    "model.add(Dense(board_size, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=64,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "0.478 0.320 0.387 0.414 0.538 0.429 0.419 0.457 0.489\n",
      "0.476 0.478 0.671 0.314 0.579 0.619 0.525 0.271 0.239\n",
      "0.747 0.380 0.377 0.721 0.462 0.463 0.423 0.827 0.383\n",
      "0.578 0.616 0.175 0.392 0.386 0.505 0.317 0.514 0.603\n",
      "0.478 0.284 0.549 0.481 0.571 0.339 0.370 0.143 0.250\n",
      "0.208 0.377 0.609 0.716 0.530 0.298 0.370 0.290 0.583\n",
      "0.234 0.441 0.669 0.479 0.477 0.420 0.478 0.491 0.767\n",
      "0.472 0.612 0.667 0.429 0.662 0.297 0.502 0.356 0.312\n",
      "0.499 0.500 0.487 0.468 0.702 0.434 0.441 0.410 0.361\n"
     ]
    }
   ],
   "source": [
    "test_board = np.array([[\n",
    "    0, 0,  0,  0,  0, 0, 0, 0, 0,\n",
    "    0, 0,  0,  0,  0, 0, 0, 0, 0,\n",
    "    0, 0,  0,  0,  0, 0, 0, 0, 0,\n",
    "    0, 1, -1,  1, -1, 0, 0, 0, 0,\n",
    "    0, 1, -1,  1, -1, 0, 0, 0, 0,\n",
    "    0, 0,  1, -1,  0, 0, 0, 0, 0,\n",
    "    0, 0,  0,  0,  0, 0, 0, 0, 0,\n",
    "    0, 0,  0,  0,  0, 0, 0, 0, 0,\n",
    "    0, 0,  0,  0,  0, 0, 0, 0, 0,\n",
    "]])\n",
    "move_probs = model.predict(test_board)[0]\n",
    "i = 0\n",
    "for row in range(9):\n",
    "    row_formatted = []\n",
    "    for col in range(9):\n",
    "        row_formatted.append('{:.3f}'.format(move_probs[i]))\n",
    "        i += 1\n",
    "    print(' '.join(row_formatted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "np.random.seed(123)\n",
    "X = np.load('/home/locutus/Desktop/dlgo_fork/deep_learning_and_the_game_of_go_with_notes/code/generated_games/features-20.npy')\n",
    "Y = np.load('/home/locutus/Desktop/dlgo_fork/deep_learning_and_the_game_of_go_with_notes/code/generated_games/labels-20.npy')\n",
    "\n",
    "samples = X.shape[0]\n",
    "size = 9\n",
    "input_shape = (size, size, 1)\n",
    "\n",
    "X = X.reshape(samples, size, size, 1)\n",
    "\n",
    "train_samples = int(0.9 * samples)\n",
    "X_train, X_test = X[:train_samples], X[train_samples:]\n",
    "Y_train, Y_test = Y[:train_samples], Y[train_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 9, 9, 48)          480       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9, 9, 48)          0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 48)          20784     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 4, 4, 48)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4, 4, 48)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               393728    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 81)                41553     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 456545 (1.74 MB)\n",
      "Trainable params: 456545 (1.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(48, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Conv2D(48, (3, 3),\n",
    "                 padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(size * size, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment with causion, if your GPU is not powerful enough, this will crash your system\n",
    "\n",
    "# model.fit(X_train, Y_train,\n",
    "#           batch_size=64,\n",
    "#           epochs=1,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_test, Y_test))\n",
    "# score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
